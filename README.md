# Jamph-Rag-Api-Umami

**Kotlin-based RAG API** that connects Umami Analytics frontend with Ollama LLM for natural language queries and SQL generation.

## ğŸ—ï¸ Architecture

```
Frontend (Umami)          Backend (RAG API)         LLM Service
localhost:5173     â†’     localhost:8004      â†’    localhost:11434
                                                    (Ollama)
```

## ğŸš€ Quick Start

### Prerequisites
- Java 21+
- Maven 3.9+
- Ollama running on `http://localhost:11434`

### 1. Start Ollama
```bash
ollama serve
# Or using Docker: docker compose --profile ollama up -d
```

### 2. Build and Run API

**Option A: Quick Start Script (Recommended for Windows)** â­
```powershell
.\start-api.ps1
```
*Automatically checks Ollama, builds, and runs the API*

**Option B: Manual**
```powershell
mvn clean package -DskipTests
java -jar target/api-1.0-SNAPSHOT-jar-with-dependencies.jar
```

**Option C: Using Maven exec**
```bash
mvn clean install
mvn exec:java -Dexec.mainClass="no.jamph.ragumami.ApplicationKt"
```

### 3. Verify
```bash
curl http://localhost:8004/health
```

## ğŸ“š Documentation

- **[API Usage Guide](README_API.md)** - Complete API documentation with examples â­
- **[Maven Setup Guide](README.mavensetup.md)** - Detailed setup instructions
- **[Integration Guide](README.integrations.md)** - Configure Ollama and frontend connections

## ğŸ“¡ API Endpoints

### Health Check
```bash
GET http://localhost:8004/health
```

### Chat Endpoint
```bash
POST http://localhost:8004/api/chat
Content-Type: application/json

{
  "message": "What is Umami Analytics?"
}
```

### SQL Generation
```bash
POST http://localhost:8004/api/sql
Content-Type: application/json

{
  "query": "Show total pageviews for all websites"
}
```

**See [README_API.md](README_API.md) for complete API documentation with JavaScript/React examples.**

## ğŸ› ï¸ Tech Stack

- **Kotlin 2.1.0** - Programming language
- **Ktor 3.0.2** - Web framework
- **LangChain4j 0.36.2** - RAG orchestration
- **Ollama** - LLM integration (llama3.2:3b)
- **Maven** - Build tool
- **Docker** - Containerization

## ğŸ”§ Configuration

Edit `src/main/resources/application.conf`:
```hocon
ollama {
    baseUrl = "http://localhost:11434"
    model = "llama3.2:3b"
}
```

Or use environment variables:
```bash
export OLLAMA_BASE_URL="http://localhost:11434"
export OLLAMA_MODEL="llama3.2:3b"
export API_PORT="8004"
```

## âœ… Current Status

**MVP Phase Complete:**
- âœ… Chat endpoint with Ollama integration
- âœ… SQL generation from natural language
- âœ… CORS configured for `localhost:5173`
- âœ… Error handling with retry logic (3 attempts, 30s timeout)
- âœ… Docker support
- âœ… NAIS deployment configuration

## ğŸ“ Project Structure

```
â”œâ”€â”€ pom.xml
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main/
â”‚   â”‚   â”œâ”€â”€ kotlin/no/jamph/ragumami/
â”‚   â”‚   â”‚   â”œâ”€â”€ Application.kt              # Main entry point
â”‚   â”‚   â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ llm/OllamaClient.kt    # LLM integration
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ rag/RAGOrchestrator.kt # RAG interface
â”‚   â”‚   â”‚   â””â”€â”€ umami/
â”‚   â”‚   â”‚       â””â”€â”€ domain/UmamiRAGService.kt
â”‚   â”‚   â””â”€â”€ resources/
â”‚   â”‚       â”œâ”€â”€ application.conf            # Configuration
â”‚   â”‚       â””â”€â”€ logback.xml                 # Logging
â”‚   â””â”€â”€ test/
â”‚       â””â”€â”€ kotlin/                         # WireMock tests
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.dev.yml
â””â”€â”€ .nais/nais-dev.yaml                     # NAIS deployment
```

## ğŸ§ª Testing

```bash
# Run tests
mvn test -DskipTests=false

# Test API manually
curl http://localhost:8004/health
curl -X POST http://localhost:8004/api/chat \
  -H "Content-Type: application/json" \
  -d '{"message":"Hello!"}'
```

## ğŸ³ Docker

```bash
# Build and run
docker compose -f docker-compose.dev.yml up

# Or build manually
docker build -t jamph-rag-api .
docker run -p 8004:8004 jamph-rag-api
```

## ğŸš¢ Deployment

Deploy to NAIS (NAV's Kubernetes platform):
```bash
# Configuration in .nais/nais-dev.yaml
# Ingress: https://jamph-rag-api-umami.ekstern.dev.nav.no
```

---

## Henvendelser

Enten:
SpÃ¸rsmÃ¥l knyttet til koden eller repositoryet kan stilles som issues her pÃ¥ GitHub

Eller:
SpÃ¸rsmÃ¥l knyttet til koden eller repositoryet kan stilles til teamalias@nav.no (som evt mÃ¥ opprettes av noenâ„¢ Windows-mennesker) eller som issues her pÃ¥ GitHub (stryk det som ikke passer).

### For Nav-ansatte

Interne henvendelser kan sendes via Slack i kanalen #teamkanal.(teamreasarchobs)